#https://wiki.owasp.org/index.php/SCG_WS_nginx#SSL_Module
# This value auto allows binding worker processes automatically to available CPUs
worker_processes auto;
# Allows binding worker processes automatically to available CPUs
worker_cpu_affinity auto;
# The number of simultaneous connections is limited by the number of file descriptors available on the system as each socket will open a file descriptor. If NGINX tries to open more sockets than the available file descriptors, it will lead to the too many opened files message in the error.log.
worker_rlimit_nofile 65535;
# error logging
error_log  /var/log/nginx/error.log;
# log warning errors
error_log /var/log/nginx/error.log warn;
# log notice errors
error_log  /var/log/nginx/error.log notice;
# log info errors
error_log  /var/log/nginx/error.log info;
# log critical errors
error_log /var/log/nginx/error.log crit;

pid        /var/run/nginx.pid;


events {
    # The maximum number of connections that each worker process can handle simultaneously. The default is 512, but most systems have enough resources to support a larger number. The appropriate setting depends on the size of the server and the nature of the traffic, and can be discovered through testing.
    worker_connections 65535;
    # This directive allows a worker to accept many connections in the queue at a time. A queue in this context simply means a sequence of data objects waiting to be processed.
    multi_accept        on;
    # With this directive worker processes will accept new connections by turn. Otherwise, all worker processes will be notified about new connections, and if volume of new connections is low, some of the worker processes may just waste system resources.
    accept_mutex        on;
    # This directive determines how long a worker should wait before accepting a new connection. Once the accept_mutex is turned on, a mutex lock is assigned to a worker for a timeframe specified by the accept_mutex_delay . When the timeframe is up, the next worker in line is ready to accept new connections.
    accept_mutex_delay  200ms;
    # This directive specifies the method to process a connection from the client. We decided to set the value to epoll because we are working on a Ubuntu platform. The epoll method is the most effective processing method for Linux platforms.
    use                 epoll;
    # This specifies the number of events that NGINX will pass to the kernel.
    epoll_events        1024;
}

http {
    # cache informations about FDs, frequently accessed files
    # can boost performance, but you need to test those values
    # This directive is disabled by default. Enable it if you want implement caching in Nginx. This directive stores metadata of files and directories commonly requested by users.
    open_file_cache max=200000 inactive=20s;
    # This directive contains backup information inside the open_file_cache directive. You can use this directive to set a valid period usually in seconds after which the information related to files and directories is re-validated again.
    open_file_cache_valid 30s;
    # Nginx usually clear information inside the open_file_cache directive after a period of inactivity based on the open_file_cache_min_uses. You can use this directive to set a minimum number of access to identify which files and directories are actively accessed.
    open_file_cache_min_uses 4;
    # You can make use of this directive to allow Nginx to cache errors  such as “permission denied” or “can’t access this file” when files are accessed. So anytime a resource is accessed by a user who does not have the right to do so, Nginx displays the same error report “permission denied”.
    open_file_cache_errors on;
    # To support larger number of server names that are defined
    server_names_hash_bucket_size  64;
    # Sets the bucket size for the server names hash tables. The default value depends on the size of the processor’s cache line.
    server_names_hash_max_size 512;
    log_format upstreamlog '$server_name to: $upstream_addr [$request] '
    'upstream_response_time $upstream_response_time '
    'msec $msec response_time $request_time ';

    upstream reactapp_service {
        # Load balancing method
        least_conn;
        # Defines a shared memory zone with the zone directive
        zone reactapp_service 64k;
        server reactapp_svc weight=10 max_fails=10 fail_timeout=60;
    }

    # redirect all http traffic to https
    server {
        listen 80 default_server;
        listen [::]:80 default_server ipv6only=on;
        server_name *.samwanekeya.com *.samwanekeya.co.ke;
        root /usr/share/nginx/html;
        index index.html index.htm index.nginx-debian.html;
        return 301 https://$host$request_uri;
    }

    server {
        listen 443 ssl;
        listen [::]:443 ssl ipv6only=on;
        server_name *.samwanekeya.com *.samwanekeya.co.ke;
        # MIME
        include /etc/nginx/mime.types;
        default_type application/octet-stream;
        # Display nginx Version number in error or http header may result in hacker to search for known vulnerability. Therefore, the version number should be removed for every http response.
        server_tokens off;
        charset utf-8;
        # This directive, by default, is disabled to allow small packets to wait for a specified period before they are sent at once. To allow all data to be sent at once, this directive is enabled.
        tcp_nodelay on;
        #  Because we have enabled tcp_nodelay directive, small packets are sent at once. However, if you still want to make use of John Nagle’s buffering algorithm, we can also enable the tcp_nopush to add packets to each other and send them all at once.
        tcp_nopush on;
        # Defines a timeout for reading client request body. The timeout is set only for a period between two successive read operations, not for the transmission of the whole request body. If a client does not transmit anything within this time, the 408 (Request Time-out) error is returned to the client.
        client_body_timeout 12;
        # Defines a timeout for reading client request header. If a client does not transmit the entire header within this time, the 408 (Request Time-out) error is returned to the client.
        client_header_timeout 12;
        # This directive sets the buffer size for the request body. If you plan to run the webserver on 64-bit systems, you need to set the value to 16k. If you want to run the webserver on the 32-bit system, set the value to 8k.
        client_body_buffer_size 16K;
        # Similar to the previous directive, only instead it handles the client header size. For all intents and purposes, 1K is usually a decent size for this directive not unless you're sending mayopic stuff via header i.e permissions.
        client_header_buffer_size 1k;
        # The maximum number and size of buffers for large client headers.
        large_client_header_buffers 2 1k;
        # The maximum allowed size for a client request. If the maximum size is exceeded, then Nginx will spit out a 413 error or Request Entity Too Large.
        client_max_body_size 64M;
        # Defines the maximum size of an entry in the MIME types hash tables.
        types_hash_max_size 4096;
        # The first parameter sets a timeout during which a keep-alive client connection will stay open on the server side. The zero value disables keep-alive client connections. The optional second parameter sets a value in the “Keep-Alive: timeout=time” response header field. Two parameters may differ. The “Keep-Alive: timeout=time” header field is recognized by Mozilla and Konqueror. The default is 75 seconds.
        keepalive_timeout 120s;
        # Configure a number of requests to keep alive for a specific period of time.  You can set the number of requests to 20 or 30.
        keepalive_requests 120;
        # if you want to disable keepalive connection for a specific group of browsers, use this directive.
        #keepalive_disable;
        #Sets a timeout for transmitting a response to the client. The timeout is set only between two successive write operations, not for the transmission of the whole response. If the client does not receive anything within this time, the connection is closed.
        send_timeout 75s;
        ssl_certificate           /etc/ssl/certs/nginx-selfsigned.crt;
        ssl_certificate_key       /etc/ssl/private/nginx-selfsigned.key;
        # enable session resumption to improve https performance
        # http://vincent.bernat.im/en/blog/2011-ssl-session-reuse-rfc5077.html
        ssl_session_cache shared:SSL:10m;
        # Specifies a time during which a client may reuse the session parameters.
        ssl_session_timeout 10m;
        ssl_buffer_size 1400;
        # generated using:# openssl dhparam -dsaparam -out /etc/ssl/dh4096.pem 4096
        ssl_ecdh_curve prime256v1:secp384r1;
        # Enables or disables session resumption through TLS session tickets.
        ssl_session_tickets on;
        # enables server-side protection from BEAST attacks
        # http://blog.ivanristic.com/2013/09/is-beast-still-a-threat.html
        ssl_prefer_server_ciphers on;
        # disable SSLv3(enabled by default since nginx 0.8.19) since it's less secure then TLS http://en.wikipedia.org/wiki/Secure_Sockets_Layer#SSL_3.0
        ssl_protocols TLSv1.2 TLSv1.3;
        # ciphers chosen for forward secrecy and compatibility
        # http://blog.ivanristic.com/2013/08/configuring-apache-nginx-and-openssl-for-forward-secrecy.html
        # Disabled insecure ciphers suite. For example, MD5, DES, RC4, PSK
        ssl_ciphers "ECDHE-RSA-AES256-GCM-SHA384:ECDHE-RSA-AES128-GCM-SHA256:DHE-RSA-AES256-GCM-SHA384:DHE-RSA-AES128-GCM-SHA256:ECDHE-RSA-AES256-SHA384:ECDHE-RSA-AES128-SHA256:ECDHE-RSA-AES256-SHA:ECDHE-RSA-AES128-SHA:DHE-RSA-AES256-SHA256:DHE-RSA-AES128-SHA256:DHE-RSA-AES256-SHA:DHE-RSA-AES128-SHA:ECDHE-RSA-DES-CBC3-SHA:EDH-RSA-DES-CBC3-SHA:AES256-GCM-SHA384:AES128-GCM-SHA256:AES256-SHA256:AES128-SHA256:AES256-SHA:AES128-SHA:DES-CBC3-SHA:HIGH:!aNULL:!eNULL:!EXPORT:!DES:!MD5:!PSK:!RC4:@STRENGTH";
        # -!MEDIUM：exclude encryption cipher suites using 128 bit encryption.
        # -!LOW：   exclude encryption cipher suites using 64 or 56 bit encryption algorithms
        # -!EXPORT： exclude export encryption algorithms including 40 and 56 bits algorithms.
        # -!aNULL：  exclude the cipher suites offering no authentication. This is currently the anonymous DH algorithms and anonymous ECDH algorithms.
        # These cipher suites are vulnerable to a "man in the middle" attack and so their use is normally discouraged.
        # -!eNULL：exclude the "NULL" ciphers that is those offering no encryption.
        # Because these offer no encryption at all and are a security risk they are disabled unless explicitly included.
        # @STRENGTH：sort the current cipher list in order of encryption algorithm key length.
        # enable ocsp stapling (mechanism by which a site can convey certificate revocation information to visitors in a privacy-preserving, scalable manner)
        # http://blog.mozilla.org/security/2013/07/29/ocsp-stapling-in-firefox/
        #Cloudflare resolver 1dot1dot1dot1.cloudflare-dns.com
        # Enables or disables stapling of OCSP responses by the server.
        ssl_stapling off;
        ssl_stapling_verify on;
        resolver             1.1.1.1 1.0.0.1 [2606:4700:4700::1111] [2606:4700:4700::1001] 8.8.8.8 8.8.4.4 [2001:4860:4860::8888] [2001:4860:4860::8844] 208.67.222.222 208.67.220.220 [2620:119:35::35] [2620:119:53::53] 9.9.9.9 149.112.112.112 [2620:fe::fe] [2620:fe::9] 64.6.64.6 64.6.65.6 [2620:74:1b::1:1] [2620:74:1c::2:2] valid=60s;
        resolver_timeout 5s;

        access_log /var/log/nginx/access.log upstreamlog;

        location / {
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;
            # Allows passing requests to another server
            proxy_pass  http://reactapp_service;
            # Sets the size of the buffer used for reading the first part of the response received from the proxied server.
            proxy_buffer_size 2k;
            # Enables or disables buffering of responses from the proxied server.
            proxy_buffering on;
            # Sets the number and size of the buffers used for reading a response from the proxied server, for a single connection.
            proxy_buffers 4 2k;
            # Limits the total size of buffers that can be busy sending a response to the client while the response is not yet fully read.
            proxy_busy_buffers_size 4k;
            # Defines a shared memory zone used for caching.
            proxy_cache off;
            # Allows starting a background subrequest to update an expired cache item, while a stale cached response is returned to the client.
            proxy_cache_background_update off;
            # Can be used along with the proxy_no_cache directive.
            proxy_cache_bypass $cookie_nocache $arg_nocache $arg_comment;
            proxy_cache_bypass $http_pragma $http_authorization;
            proxy_no_cache $cookie_nocache $arg_nocache $arg_comment;
            proxy_no_cache $http_pragma $http_authorization;
            # Disable directory listing
            autoindex off;
            autoindex_exact_size off;
        }

        # additional config
        include /etc/nginx/general.conf;
        include /etc/nginx/security.conf;
        }
}
